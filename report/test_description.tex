\section{Test description}
\label{section:test_description}

In this section I will describe which metrics I am going to use to compare the different algorithms. Having specified these I will describe the tests in detail.

\subsection{Metrics}

The metrics I will measure in the tests will be 
\begin{description}
\item[Number of hops:] The number of hops from the source to the sink. For this I will measure the maximum number of hops, the minimum number of hops, as well as the average. I feel the number of hops is the most important metric, since it both details how many nodes that have to expend energy before the message arrives at the node, how long it takes for the message to arrive at its destination, and how great the risk is that the network topology will make it impossible for the message to arrive (assuming, of course, that the message could arrive when it was sent).

\item[Time:] The amount of time spent sending the message from the source to the sink. I will likewise measure the maximum, minimum and average time spent. It is clear that the faster a message arrives at its sink, the better.

\item[Percentages of successfully arrived messages:] While most routing algorithms guarantees that the message will always arrive, this is not always the case . The best example of a routing algorithm that does not have this guarantee is the greedy routing algorithm (see section~\ref{section:greedy} p. \pageref{section:greedy}). Also, since we are trying to simulate mobile nodes with limited energy storage, critical parts of the topology may be fail, making it impossible for the message to arrive.
\end{description}

For the number of hops and the  amount of time I will record the maximum, the minimum and the average value. The main value for comparison will be the average value, but I feel that recording both the maximum and the minimum values will give me better information about the average.

\subsection{Input parameters}
\label{section:input_parameters}
In order to perform the tests I will need to define the parameters and their range for the different tests.
\begin{description}
\item[Movement model:] The topology is clearly going to be influenced by the way that the nodes move, therefore it would be interesting to test out several models, to see the strengths and weaknesses of the different routing algorithms.

\item[Routing Algorithms] 

\item[Amount and data-transmission type:] In real world situations there will be different levels of traffic on the network, and therefore to test it we must likewise simulate these differences. The choice of transmission protocol is also important.

\item[Size of the simulation area:] The size of the simulation area has a direct influence on how far apart the nodes can move and how many nodes are needed for a given node density. Everything else being equal, a larger simulation area will make the network less robust.

\item[Number of nodes:] It is clear that denser node distribution, everything else being equal, will give a more robust network.

\item[Percentage of nodes failing/leaving the network:] Since we are dealing with a \ac{manet}, it is clear that a nodes may leave the network or fail (either due to equipment failure or lack of power). 

\item[Percentage of nodes entering the network:] In a \ac{manet} we have to assume that nodes can enter the network.
\end{description}

\subsection{Actual parameters}
As I have now detailed in section~\ref{section:input_parameters} which parameters it would be useful to vary, I will in this subsection detail the actual value of the different parameters. 

\begin{description}
\item[Movement models:] \hide{DisasterArea \cite{disasterArea} and} Gauss-Markov \cite{MobilityAdHocResearch} with the trace created through the use of the BonnMotion tool \cite{toilers} use to create the movement files which can then be imported into ns-2\footnote{For the script that generates the movement files, please see \texttt{src/MotionCode/Gauss-Markov.py}}.
\item[Amount and Data-transmission type:] 512 kB through a TCP connection
\item[Size of simulation area:] 500 by 500 units and 1000 by 1000 units
\item[Routing algorithms:] GOAFR \cite{gopher}, GPSR \cite{gpsr}, Greedy \cite{gopher}, DSDV \cite{DSDV}
\item[Number of nodes:] 100 to 3000 nodes in increments of 100 nodes, giving me 30 data-points that will be used to analyse the success of the routing algorithms. 
%\item[Nodes failing:] 0\%, 10\%, 40\%
%\item[Nodes entering:] 0\%, 30\%
\item[Time:] 1 minute (60 seconds)
\item[Amount of nodes transmitting:] 33\% of the network
\end{description}

\subsection{Routing algorithm description}
\label{section:routing_algorithm}
In this description of the chosen routing algorithms, I will assume by default that there exists a path from the source to the sink, and if needed I will detail how the algorithm handles the cases where no such path exists.

Since I have already explained how the Greedy routing works in \ref{section:greedy}.

\subsubsection{GOAFR and GOAFR+}

GOAFR \cite{gopher} (Greedy Other Adaptive Face Routing) and GOAFR+ \cite{gopher+} (a refinement on GOAFR) are multi-stage geometrical algorithms. The algorithms are based on Greedy routing (see section~\ref{section:greedy} on p. \pageref{section:greedy}) and Adaptive Face Routing, with an adaptive ellipse $\epsilon$ as the boundary for the message. The description in the following paragraphs uses information from \cite{gopher}.

As an integral part of the algorithm, GOAFR includes an ellipsis $\epsilon$ that that the message has to keep inside, in order to avoid having the message going astray. $\epsilon$ is created so that its forci are the source $s$ and the sink $t$, and so that its semi-major axis starts out being $2 * |\overline{st}|$. Using the formula for forci
\eqa{
F = \sqrt{j^2 - n^2}
}
where $F$ is the distance from each forci to the centre, $j$ is the semi-major axis (major radius), and $n$ is semi-minor axis (minor radius) so in this case we have
\eqa{
F &=& \sqrt{j^2 - n^2}\\
\frac{|\overline{st}|}{2} &=& \sqrt{j^2 - n^2}\\
\left(\frac{|\overline{st}|}{2}\right)^2 &=& j^2 - n^2\\
n^2 &=& j^2 - \left(\frac{|\overline{st}|}{2}\right)^2\\
n &=& \sqrt{j^2 - \left(\frac{|\overline{st}|}{2}\right)^2}\\
}
which we then can use to calculate the semi-minor axis. Depending on the execution of GOAFR the major axis of $\epsilon$ might grow, as detailed in the next two paragraphs.

Having thus laid the groundwork I can now describe GOAFR:
\begin{enumerate}
\item Make the ellipsis based on the sink and the source.
\item Perform Greedy routing as described in section~\ref{section:greedy} on p. \pageref{section:greedy}. If the greedy algorithm sends the message beyond the bound of $\epsilon$, then the longest axis of $\epsilon$ is doubled. If the message arrives at the sink, then the message is handed over to the node and the algorithm terminates. If the message arrives at a local minimum (see section~\ref{section:greedy} for an explanation), go to step 3.
\item Since we have arrived at a node $u$ local minimum, we first store $u$ as both $u_{local min}$ and as $u_{closest node}$ in the message header, to indicate that it is both the node we started routing around the face as, but also the node that is closest to the sink. We then use Adaptive Face routing (which uses the right-hand rule --- see section~\ref{right-hand-rule} on p. \pageref{right-hand-rule}) to traverse the face, and for each node $v$ we encounter we check to see if it is closer to the sink than the current value of $u_{closest node}$, if so, we set $u_{closest node}$ to be $v$. 

If the message is about to go outside of $\epsilon$ for the first time, then the message reverses direction and the message tries to traverse the face in the other direction (skipping past $u_{local min}$) without stopping). If the message encounters $\epsilon$ for the second time, then the longest axis of $\epsilon$ is doubled and the message is forwarded as normal.

At some point the message will either arrive back at $u_{local min}$ or find the sink. If the message arrives back at $u_{local min}$ after having gone outside $\epsilon$ an even number of times, we then go to step 4. If the message arrives at the sink, then the message is handed over to the sink and the algorithm terminates.
\item The message is now forwarded to $u_{closest node}$ we found in the last step, by using the same face routing as before. Once we arrive at $u_{closest node}$ we go to step 2.
\end{enumerate}

GOAFR+ works similarly to GOAFR, with the difference being the introduction of 2 variables $p$ and $q$. While doing the adaptive face routing from the local minimum node $u_{local min}$, the algorithm keeps track of how many nodes encountered that are closer to the sink than $u_{local min}$ in the variable $p$ and how many are farther away from the sink than $u_{local min}$ in the variable $q$.
A special action is then taken if
\begin{enumerate}
\item If the message arrives at the edge of $\epsilon$ for the first time, then the message turns back and explores the face in the other direction. 
\item If the message arrives at the edge of $\epsilon$ for the second time, and no nodes have been found to be closer to the sink than $x$, then the major axis of $\epsilon$ is doubled. Otherwise the message is sent to the node closest to the sink and the greedy routing is resumed.
\item If at any point $p > \rho q$, where $\rho$ is a constant defined before routing starts, then route the message to the node closest to the sink and begin greedy routing again.
\end{enumerate}

Both GOAFR and GOAFR+ has proved to be theoretical asymptotically worst-case optimal and average-case efficient. Due to space demands I will not try to prove these claims here, but will instead refer the interested reader to \cite{gopher+, gopher}.

Due to time constraints I have only been able to implement GOAFR in ns-2, and so will only use that in the tests.

\subsubsection{GPSR}
\tikfig{gpsr}
{A demonstration of the GPSR routing algorithm. The grey background with grey nodes indicates when the GPSR algorithms is in the Greedy phase and the the black nodes with the black background indicates when the algorithm is running in perimeter phase}

\label{section:gpsr}
Greedy Perimeter Stateless Routing is a routing algorithm that uses a hybrid of Greedy routing and face routing. The idea is to use Greedy routing as much as possible, and only use the face routing recover from situations where it reaches a situation where the Greedy routing fails. The algorithm will use the right-hand-rule (see section~\ref{right-hand-rule} on p. \pageref{right-hand-rule}) to route the messages in perimeter mode to ensure they stay within the same face. I base all the description in this subsection on \cite{gpsr}.

If we let $x$ be the point where the Greedy routing fails, and $t$ be the sink, then the gist of the perimeter routing is to route through the faces that are intersected by the line-segment $\overline{xt}$, in order to find a point that is closer to $t$ than $x$, and possibly recover. In order to do this the algorithm will explore each face sequentially, moving on to the next face when it encounters a node or, more likely, an edge that is intersected by $\overline{xt}$. 

In order for the routing to work the algorithm relies on 4 values:
\begin{description}
\item[$t$:] The sink, which contains its own coordinates
\item[$L_p$:] The node where the algorithm went from Greedy routing to Perimeter routing. This value is overwritten if the routing goes back to Greedy routing and then back to Perimeter routing. This, together with $t$, is used to create the line-segment $\overline{L_pt}$, that is used to signal when the message is close enough to $t$ to move to the next face.
\item[$L_f$:] The point on $\overline{L_pt}$ where the message entered the current face. Most of the time this will not be the position of a node, but rather a point on an edge between the face whose perimeter the message has just explored, and the next face. 
\item[$e_0$:] The first edge the message traversed on the current face. This is used as the termination condition for the perimeter exploration in the case where $t$ is unreachable. 
\end{description}

also, in the following let $f$ denote the current face we are routing on.

\begin{enumerate}
\item The algorithm begins with greedy routing until it either reaches the sink, in which case it terminates, or it reaches a local minimum and therefore fails. In the case of failure the message enters perimeter mode and goes to step 2.
0\item The message will enter perimeter routing and record its current node as both $L_p$ and $L_f$, and store the line-segment $\overline{L_pt}$, which we will use throughout our routing. The edge counter-clockwise to $L_p$ is stored in $e_0$. The algorithm goes to step 3
\item Let $p$ be the current node, if $|\overline{pt}| < |\overline{L_pt}|$ we have reached a node closer to the sink than the local minimum, and we continue with our Greedy routing --- the algorithm goes to step 1. If on the other hand $p$ is farther away from the sink than $L_p$, the message is transferred to the counter-clockwise node $q$ on $f$. If $\overline{pq} == e_0$ then we have come full circle, and there exist no path to the sink $t$, so drop the message. If on the other hand either $q$ or $\overline{pq}$ is intersected by $\overline{L_pt}$, then transmit the message to $q$ and go to step 4, otherwise just transmit the message and go to step 3.
\item Let $p$ be the current node. Set $L_f$ to $p$ and switch to the next face. Let $q$ be the counter-clockwise neighbour of $p$ on the new face and set $e_0$ to $\overline{pq}$. Go to step 3. 
\end{enumerate}

\subsubsection{DSDV}


\subsection{Mobility models}

For the mobility models I have only chosen to test Gauss-Markov, which I from \cite{MobilityAdHocResearch} found to be a good algorithm for simulating a movement pattern\footnote{Not to mention was implemented by the same team that build the Bonnmotion movement tool} that seems rather random. I would have liked to test the Disaster Area movement pattern found in \cite{disasterArea}, but I found it difficult to get the bonnMotion tool to generate the movement, as well as unsure on which definitions would create an interesting model for the different algorithms to be tested on\footnote{In order to create the a disaster area movement simulation several different zones have to be defined -- e.g. a zone for the disaster, a zone for the triage, treatment and so on.}. 

The script I have used to create the needed ns-2 mobility data can be found in the \texttt{src/MotionCode} directory.

\subsection{Traffic}
I chose the TCP connection on the ground that I would like to stress tests the different routing algorithms, and since TCP requires more back-and-forth than UDP (and is necessary for transfer of files, and not just steaming of video/audio or the state of a multi-player game).

Ns-2.33 comes with its own Traffic generation program cbrgen.tcl\footnote{Located in the \texttt{indep-utils/cmu-scen-gen} directory}, that I have used to generate the traffic for these tests. The script I have used to create the needed ns-2 traffic files can be found in the \texttt{src/Traffic} folder.

\subsection{Limited-range spanner tests}
\label{section:test_desc_spanners}
In this section I will detail how I have chosen to set up the limited-range spanner tests for the three different graphs: non-planar, the \acp{gabe} and the \acp{rng}.

\subsubsection{Creation of the graphs}
It is clear that we must create several graphs of several different number of nodes, as it otherwise is impossible to gain a proper perspective on how well the \ac{gabe} and the \ac{rng} stack up against the non-planar graph. In order to better describe the graphs I will use, I will introduce the notion of \emph{node-sets}, which is a finite set of nodes, where all nodes have a x- and y-coordinate and a transmit distance. Also of impotence is the concept of \emph{node-category}, which is a set of node-sets, where all node-sets in any given node-category has the same amount of nodes in them. 

In order to do this test I will first have to make several decisions:
\begin{itemize}
\item Decide upon whether we are going to uniformly distribute the nodes or if some sort of clustering should be done. 
\item How many node-categories I will have to create, balancing the need for data-points and their spread with the time they will take to create and analyse.
\item Decide upon the density for the node-categories --- if indeed there should be a fixed density for them, or if the density should be random.
\item The number of graph I will generate and the number of test I will perform for each graph in order to get enough test data to properly gauge the underlying data.
\end{itemize}

I have not encountered any specific point clustering algorithm in the literature besides the various mobility models (see \cite{disasterArea, MobilityAdHocResearch}) which has lead me to place the nodes uniformly in the plane. The justification of this was both the fact that part of this investigation was an experimental look into how the non-planar graph would behave compared to the \ac{gabe} and the \ac{rng}, and not just about \acp{manet}. In retrospect I can see that using data from the mobility model would proper would have given a better picture and would most likely have made it possible for me to cut down on the number of graphs that would have to have been generated (since the graphs would be representative of the the mobility model, and not just uniformly distributed). See section~\ref{section:future_work} for my recommendation for future comparisons between the graphs.   
Since I have chosen to uniformly distribute the nodes I will need a large number of tests in order for the underlying properties of the three types of graphs to emerge. Therefore I will therefore have to limit the number of node-categories so that I will be able to process all the tests. I will therefore chose to limit myself to 7 node-categories with the following number of nodes: 100, 250, 500, 1000, 2500, 5000 and 7500 nodes.

I feel this is a good compromise between having a reasonable number of data-points and big enough spread, while still being able to compute them in a reasonable amount of time. The nodes are going to be placed uniformly in the plane, with the lower bound of their coordinates being 0, and the upper bound depending on the number of points in the graph. No two points will have same the coordinates. 

Since we are dealing with limited-range spanners, the value of the node density and the radio-range of the nodes becomes important\footnote{If I had made the choice to use the mobility models or a cluster node algorithm, these factors would still have an impact, but properly less}. Different densities and radio-ranges would heavily influence the outcome of the results, as a high node density/radio-range would favour the non-planar graph over the two other graph types, while a low density/radio-range would create heavily disconnected graphs in all three cases. Since having many disconnected graphs would make testing difficult, I have tried to find combination that would give me a low number of connected components pr. node-set, while still keeping the density reasonably low. From several experiments this let me to a density of 0.01 nodes pr. square unit and a radio range of 20 units, and make the space the nodes are placed over a function of the number of nodes. Specifiably, if we let $x$ be the length of the sides in a square and $num$ be the number of nodes, then we have that the density is
\begin{eqnarray}
\frac{num}{x^2} &=& 0.01 \\
0.01 * x^2 &=& num \\
x^2 &=& 100 * num\\
x &=& \sqrt{100 * num}  
\end{eqnarray}
meaning that in practise the graphs are squares in the plane with the following dimensions, which will also be the upper limits on their coordinates:

\begin{tabular}{lrrrrrrr}
Number of nodes: & 100 & 250 & 500 & 1000 & 2500 & 5000 & 7500 \\
Width/height:    & 100 & 158 & 223 &  316 &  500 &  707 &  866  
\end{tabular} 

\subsubsection{Tests to be performed}
\label{section:spanner_tests_performed}
In order to check the limited-range spanner for the three graphs, I will randomly pick two different nodes, a \emph{node-pair}, that are connected in the non-planar graph and record the shortest number of hops (the \emph{Unit distance}), as well as the shortest distance based on the weight between the two nodes (the \emph{Euclidean distance}). I feel both values are worth finding, as the number of hops is directly applicable to \acp{manet}, while the Euclidean distance is interesting from a more theoretical perspective, and will therefore also be recorded.

I will do this for all three types of graphs, and record whether or not a path exist between the node-pair in the \ac{gabe} or the \ac{rng}. If it is indeed the case that there are cases where the two alternative planar graphs removes paths, that would create an element of risk by employing them, instead of the non-planar graph. On these grounds I will record and display the number of missing paths the analysis is able to find.

In both cases I will use Dijkstra's algorithm to find the smallest Euclidean/Unit distance. The implementation I uses is a modified version originally made by David Eppstein\footnote{dijkstra.py was found at \url{http://code.activestate.com/recipes/119466-dijkstras-algorithm-for-shortest-paths/} --- last accessed 17/8 2011. Modification was to allow to check for Unit distances without having to modify the graph weights -- see function ``UnitDijkstra''. Support library prirodict.py (also by David Eppstein, and not modified) was found at \url{http://code.activestate.com/recipes/117228/} --- last accessed 17/8 2011. The files can be found in \texttt{src/graph\_support}}.

\subsubsection{Analysis}
For each node-pair tested for the graphs I will find the total distance passed for all the node-pairs, the average distance, the average maximum and minimum distance for all the tests\footnote{I feel it is necessary to use the average since there may be outliers that easily could skew the results} and lastly the standard deviation\footnote{For the same reasons as I included the average minimum and maximum}. Likewise I will find the total unit distance, the average unit distance, the average maximum and minimum unit distance and standard deviation. Since one of the advantages of the \ac{gabe} and the \ac{rng} is that they have fewer neighbours, I will also find the total number of neighbours, the average, max- and minimum number of neighbours and standard deviation. I will also include the average number of connected components (across all the 500 non-planar graphs), which will tell us how connected the graphs are.

\subsubsection{Size of the test}
Since the node-sets that we are going to generate the graphs from are going to distributed uniformly, I feel that in order to gain a proper picture of the situation we need to generate many node-sets, so that any underlying pattern can show it self. Therefore I have decided to generate 500 different uniformly distributed node-sets. For each node-set I will then generate one non-planar graph, one \ac{gabe}, and one \ac{rng}, meaning that for each node node-category I  generate 500 graphs for the non-planar, \ac{gabe} and \ac{rng} (for a total of 1500 graphs for each - except for node-category 7500 and 10000, for which I only have been able to generate 250 for each, due to time constraints). Each node-set is then used to generate the three types of graph. For each node-set I then generate 100 node-pairs. I feel that this will give me an reasonable amount of data to analyse, while still being computable for the larger number of nodes.

\subsection{Network simulators}
\label{section:network_simulators}

In order to perform my network tests, I will need a network simulator. I have chosen not to make my own, since it will take too much time, and will make it much harder to compare my results with that of others. I have been able to identify 4 big network simulators: ns-2, ns-3, GloMoSim and the Opnet Modeler.

\begin{description}
\item[ns-2:] ns-2 is a discrete event network simulator. The latest version I have been able to find is version 2.34 from 2009. Ns-2 uses the programming language Otcl for most of its non-core engine files --- routing algorithms and the scenario files that configures how the test is to be performed. Otherwise everything is written in C++.
\item[ns-3:] ns-3 is the successor to ns-2 in an attempt to make a clean break from the architecture of ns-2 and its reliance on Otcl in favour for Python.
\item[GloMoSim:] GloMoSim is a parallel discrete-event simulator. GloMoSim is an old simulator, version 2.3, last updated December 2001\footnote{GloMoSim can be found at \url{http://pcl.cs.ucla.edu/projects/glomosim/academic/download.html} --- last accessed the 31/7 2011}. GloMoSim uses the programming language \emph{Parsec}, a dialect of C, to write most of the non-core engine files -- such as routing algorithms. 
\item[Opnet Modeler:] Opnet is a commercial network simulator. Every layer of the network stack has to be modelled as a finite state machine \cite{MANcom}. 
\end{description}

From \cite{MANcom} it is clear that the Network simulators gives widely different results. Since it is not clear which of the simulators which gives the result that is closest to reality, the parameters I will have to apply to find the best network simulator are: The license of the network simulator. When it was last updated, how configurable any given simulation is, whether or not it supports wireless routing, how much memory it consumes while running, which languages are required to implement a new protocol, how many programming languages are required to implement a new scenario, and whether new routing protocols can just be plugged in, or if the entire network simulator has to be recompiled. For Configurable and memory I will use A, B and C, with A as the highest and C is the lowest, to grade them\\
\begin{scriptsize}
\begin{minipage}{15.0cm}
\begin{tabular}[4]{lllll}
                          & ns-2      & ns-3      & GloMoSim & Opnet Modeler \\
\hline
License:                  & GNU GPL   & GNU GPL   & Academic & People in academic world can apply\\        &           &           &          & for a monthly renewable license \\
Last updated              & 20/6 2011
\footnote{\scriptsize{See \url{http://sourceforge.net/projects/nsnam/} --- last accessed 31/7 2011}} & May 2011
\footnote{\scriptsize{See \url{http://www.nsnam.org/ns-3-11/} --- last accessed 31/7 2011}} & 19/12 2001
\footnote{\scriptsize{See \url{http://pcl.cs.ucla.edu/projects/glomosim/academic/download.html} --- last accessed 31/7 2011}}  & \\
Configurability           & A         & A         & B         & Unknown, but A suspected\\
Support for wireless      & Yes       & Yes       & Yes       & Yes \\
Memory requirements       & A         & B         & B         & Unknown\\
Req for routing protocol  & C++ and OTCL & C++    & Parsec    & None - uses built-in GUI\\
Req for new scenario      & OTCL      & Python    & Custom    & Unknown \\
Plug-in or Recompile      & Recompile & Recompile & Recompile & Plug-in, as it uses the built-in GUI
\end{tabular}
\end{minipage}
\end{scriptsize}

All of the simulators have simple node mobility models built-in. I have however chosen to use a third-party program, BonnMotion\footnote{BonnMotion has been produced as a collaboration between the University of Bonn and the Toilers at \url{toilers.mines.edu} -- last accessed the 16/5 2011} on the grounds that it supports a far greater range of mobility models\footnote{Such as ``Disaster Area'', which I have not found built in implemented in any of the network simulators}, and it enables me to store, and process, the movement traces.

Based on the above, I have chosen to use the ns-2 simulator, since it is far more customisable than both ns-3 and GloMoSim, is Open Source and referred to in much of the literature I have read \cite{directed, gpsr, energyConservation, two-tier} and is still being supported, unlike GloMoSim. However, while the 2.34 version is the latest, I have opted to use version 2.33 from 2008, since this is the only version I have been able to find that has a working copy of GPSR\footnote{Found at \url{http://www.cn.uni-duesseldorf.de/alumni/kiess/software/hls-ns2-patch} --- last accessed 31/7 2011} with a location system. The location system in question is the \ac{hls} which borrows many concepts from the \ac{gls} \cite{hls}. Thanks to the working version of GPSR, I have been able to comparatively quickly implement both a Greedy routing algorithm and the GOAFR routing algorithm, which I will test amongst others. 

I have opted not to port the code to ns-2.34 on the grounds that I fear that I might introduce subtle bugs that might take a long time to find and correct. Since this is only one version behind the current stable release, I find this acceptable.
